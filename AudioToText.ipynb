{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🗣️ [**AudioToText**](https://github.com/Carleslc/AudioToText)\n",
        "\n",
        "[![Donate](https://www.ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/carleslc)\n",
        "\n",
        "### 🛠 [Whisper by OpenAI](https://github.com/openai/whisper)\n"
      ],
      "metadata": {
        "id": "YHM2u5nOmUo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Step 1] ⚙️ Install the required libraries\n",
        "\n",
        "Click ▶️ button below to install the dependencies for this notebook."
      ],
      "metadata": {
        "id": "zwB0uQQhmdmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFBIl02Q9eTF"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!apt-get install libcudnn8\n",
        "import os\n",
        "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
        "#@title { display-mode: \"form\" }\n",
        "import subprocess\n",
        "from sys import platform as sys_platform\n",
        "\n",
        "# Install ffmpeg if not present\n",
        "status, ffmpeg_version = subprocess.getstatusoutput(\"ffmpeg -version\")\n",
        "if status != 0:\n",
        "    if sys_platform == 'linux':\n",
        "        !apt-get -qq update && apt-get -qq install -y ffmpeg\n",
        "    else:\n",
        "        print(\"Install ffmpeg: https://ffmpeg.org/download.html\")\n",
        "else:\n",
        "    print(ffmpeg_version.split('\\n')[0])\n",
        "\n",
        "# Install faster-whisper and other dependencies\n",
        "print(\"Installing Python dependencies...\")\n",
        "!pip install --upgrade pip\n",
        "!pip install faster-whisper deepgram-sdk pydub typing-extensions\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install openai-whisper\n",
        "!pip install srt requests tqdm googletrans==4.0.0rc1 httpx aiometer\n",
        "# https://stackoverflow.com/a/77671445\n",
        "!apt install libcublas11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Step 2] 📁 Upload your audio files to the Files folder\n",
        "\n",
        "⬅️ Files folder in Google Colab is on the left menu\n",
        "\n",
        "Almost any audio or video file format is [supported](https://gist.github.com/Carleslc/1d6b922c8bf4a7e9627a6970d178b3a6)."
      ],
      "metadata": {
        "id": "lnhrnnnCmkih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "import os\n",
        "import torch\n",
        "import math\n",
        "from faster_whisper import WhisperModel\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "# select task\n",
        "task = \"Transcribe\" #@param [\"Transcribe\", \"Translate to English\"]\n",
        "task = \"transcribe\" if task == \"Transcribe\" else \"translate\"\n",
        "\n",
        "# set model\n",
        "use_model = \"large-v2\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
        "\n",
        "# other parameters\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "coherence_preference = \"More coherence, but may repeat text\" #@param [\"More coherence, but may repeat text\", \"Less repetitions, but may have less coherence\"]\n",
        "api_key = '' #@param {type:\"string\"}\n",
        "\n",
        "# Set device\n",
        "if api_key:\n",
        "    print(\"Using API\")\n",
        "    from pydub import AudioSegment\n",
        "    from pydub.silence import split_on_silence\n",
        "else:\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using {'GPU' if DEVICE == 'cuda' else 'CPU ⚠️'}\")\n",
        "    if DEVICE == \"cuda\":\n",
        "        !nvidia-smi -L\n",
        "    else:\n",
        "        print(\"Not using GPU can result in a very slow execution\")\n",
        "        print(\"Ensure Hardware accelerator by GPU is enabled in Google Colab: Runtime > Change runtime type\")\n",
        "\n",
        "# Load model\n",
        "if not api_key:\n",
        "    model_size = use_model\n",
        "    print(f\"\\nLoading {model_size} model...\")\n",
        "    model = WhisperModel(model_size, device=DEVICE, compute_type=\"float16\" if DEVICE == \"cuda\" else \"int8\")\n",
        "    print(f\"Model {model_size} loaded successfully.\\n\")\n",
        "\n",
        "# Set options for faster-whisper\n",
        "options = {\n",
        "    'task': task,\n",
        "    'beam_size': 5,\n",
        "    'vad_filter': True,\n",
        "    'initial_prompt': prompt or None,\n",
        "    'word_timestamps': False,\n",
        "    'language': None # Auto-detect language\n",
        "}"
      ],
      "metadata": {
        "id": "K8jmq-jymn30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title { display-mode: \"form\" }\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "# Define the root directory to search for video files\n",
        "directory_to_scan = '.'  # Scans the current directory. Change this if needed.\n",
        "\n",
        "# List of video file extensions to look for\n",
        "video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.flv', '.webm', '.mka']\n",
        "\n",
        "# set output folder\n",
        "output_dir = \"audio_transcription\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# --- Find video files, check for existing subtitles, and sort them ---\n",
        "audio_files = []\n",
        "all_files = glob.glob(os.path.join(directory_to_scan, '*'))\n",
        "all_files.sort()  # Sort the files alphabetically\n",
        "\n",
        "for file_path in all_files:\n",
        "    if os.path.isfile(file_path):\n",
        "        name, ext = os.path.splitext(os.path.basename(file_path))\n",
        "        if ext.lower() in video_extensions:\n",
        "            # Correct path for checking existing SRT file\n",
        "            srt_output_path = os.path.join(output_dir, f\"{name}.srt\")\n",
        "            if os.path.exists(srt_output_path):\n",
        "                print(f\"Skipping {os.path.basename(file_path)}: Subtitle file already exists.\")\n",
        "            else:\n",
        "                audio_files.append(file_path)\n",
        "\n",
        "if not audio_files:\n",
        "    print(\"No new video files found to process.\")\n",
        "else:\n",
        "    # Perform transcription\n",
        "    if task == \"translate\":\n",
        "        print(\"-- TRANSLATE TO ENGLISH --\")\n",
        "    else:\n",
        "        print(\"-- TRANSCRIPTION --\")\n",
        "\n",
        "    # Helper function to correctly save a single SRT file\n",
        "    def save_srt_file(result, output_dir, output_file_name):\n",
        "        writer = get_writer(\"srt\", output_dir)\n",
        "        # Note: whisper's get_writer automatically adds the extension.\n",
        "        writer(result, output_file_name)\n",
        "        output_file_path = os.path.join(output_dir, f\"{output_file_name}.srt\")\n",
        "        print(f\"Saved: {output_file_path}\")\n",
        "\n",
        "    # Process and save each file individually\n",
        "    for audio_path in audio_files:\n",
        "        print(f\"\\nProcessing: {os.path.basename(audio_path)}\\n\")\n",
        "\n",
        "        if not api_key:\n",
        "            # Faster-Whisper\n",
        "            segments, info = model.transcribe(audio_path, **options)\n",
        "\n",
        "            transcription_text = []\n",
        "            result_segments = []\n",
        "            for segment in segments:\n",
        "                transcription_text.append(segment.text)\n",
        "                result_segments.append({\n",
        "                    'start': segment.start,\n",
        "                    'end': segment.end,\n",
        "                    'text': segment.text\n",
        "                })\n",
        "\n",
        "            result = {\n",
        "                'text': \"\\n\".join(transcription_text),\n",
        "                'segments': result_segments,\n",
        "                'language': info.language\n",
        "            }\n",
        "            print(f\"Detected language: {result['language'].title()}\\n\")\n",
        "\n",
        "            for segment in result_segments:\n",
        "                print(f\"[{segment['start']:.2f} --> {segment['end']:.2f}] {segment['text']}\")\n",
        "\n",
        "        else:\n",
        "            # API processing logic would go here\n",
        "            pass\n",
        "\n",
        "        # --- Saving logic for a single SRT file ---\n",
        "        try:\n",
        "            # Corrected line: pass 'name' to the helper function.\n",
        "            save_srt_file(result, output_dir, os.path.splitext(os.path.basename(audio_path))[0])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not save {os.path.splitext(os.path.basename(audio_path))[0]}.srt: {e}\")\n",
        "\n",
        "    # --- New logic: Create a zip file of the subtitles ---\n",
        "    zip_filename = \"subtitles.zip\"\n",
        "    zip_path = os.path.join('.', zip_filename)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zf:\n",
        "        print(f\"\\nCreating {zip_filename}...\")\n",
        "        for root, dirs, files in os.walk(output_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zf.write(file_path, os.path.relpath(file_path, output_dir))\n",
        "\n",
        "    print(f\"All subtitles have been archived into {zip_filename}.\")"
      ],
      "metadata": {
        "id": "X_zCSuHVm1YC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
